{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 레이어의 이해, Embedding, Recurrent\n",
    "\n",
    "리니어 레이어와 컨볼루션 레이어에 대해 살펴보았다. 이제 가중치 weight 개념을 이해 했다면, Embedding 레이어와 RNN 레이어와 LSTM의 동작방식에 대해 배워볼 차례이다.\n",
    "\n",
    "## 희소 표현\n",
    "[사과, 바나나, 배]를 표현할 때, [0,1,2]과 같이 단어를 매핑하거나, 둥글다, 색상으로 [[0,0],[1,1],[0,1]]처럼 특정 차원에 단어 혹은 의미를 매핑하는 방식을 희소표현이라 한다.\n",
    "\n",
    "## 단어의 분산표현\n",
    "모든 단어를 고정차원(e.g 256차원)의 백터로 표현하면 어떨까? 차원이 의미나 단어를 의미하지 않는다고 하고, 유사한 맥락만 보고 그러한 맥락의 단어가 의미도 비슷할 것이라는 분포가설에 따라 표현하는 것이다.\n",
    "\n",
    "'나는', '을 먹는다' 사이에 들어가는 단어들은 유사한 의미를 갖겠죠? 그렇게 하면 유사한 단어들의 백터 사이의 거리를 가깝게 하고 그렇지 않은 단어들끼리 멀어지도록 조정하면서 단어를 백터로 표현하는 것이 분산표현이다.\n",
    "\n",
    "## Embedding 레이어\n",
    "분산 표현을 구현기 위해 n개의 단어 k차원으로 표현하는 n*k 형태의 분산 표현 사전을 만들고, 가중치의 파라미터 값을 학습을 통해 찾아가도록 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding 레이어 학습 방법\n",
    "임베딩 레이어는 케라스 신경망을 통해서 학습된다. 케라스에서 손실함수를 줄여주는 방식으로 학습할 수 있으며, 콘볼루션 레이어 등과 다른 점은, 입력값이 수치적인 의미를 갖지 않고 인덱스와 같은 의미라서, 결과 값이 입력값의 수학적인 계산이 의미를 갖지 않는다. 그래서 케라스의 임베딩 레이어는 word2vec과 같은 방식으로 동작한다고 볼 수 없다. word2vec은 단어들의 문맥을 잡기위한 임베딩 학습을 위한 시도하는 특별한 신경망 구축이 필요하다.\n",
    "케라스 임베딩 레이어는 손실함수를 줄이기 위해서 학습한다. 감정분석을 한다고 보면, 임베딩 학습이 완벽한 단어 의미를 찾고, 문맥을 잡는다기 보다는 그들의 감정의 양극성을 확인하는 형태로 임베딩 레이어를 학습한다.\n",
    "\n",
    "임베딩 레이어를 학습하기 위해서는 word2vec, skip_gram, Glove or CBOW 등이 활용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding 레이어 톺아보기\n",
    "\n",
    "간단하게 정리하면 컴퓨터용 단어사전이다. 단어를 n개 쓴다고 전달만 하면 컴퓨터가 알아서 사전을 만들고 분산표현을 차근차근 없데이트 합니다.\n",
    "\n",
    "## 단어 간 유사도를 파악하는 방법\n",
    "0,1만 인식하는 컴퓨터에게 자연어를 처리하도록 하는 자연어 처리, NLP는 어떻게 텍스트에서 유의미한 데이터를 추출해서 처리하는 것일까?\n",
    "\n",
    "## 1. 가장 간단하고 원시적인 원-핫 인코딩\n",
    "N개의 단어를 N차원의 백터로 표현하는 것이다. 가장 정확하게 분류가 가능하지만, 단어의 크기에따라 차원이 너무 커지고, 일정수준이 넘어가면 분류기 성능이 되려 0으로 수렴한다는 차원의 저주도 고려해야한다. 또한, 이방식은 단어들의 유사도를 파악하지는 못한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-11 13:12:39.612500: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-10-11 13:12:39.612919: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "vocab = {      # 사용할 단어 사전 정의\n",
    "    \"i\": 0,\n",
    "    \"need\": 1,\n",
    "    \"some\": 2,\n",
    "    \"more\": 3,\n",
    "    \"coffee\": 4,\n",
    "    \"cake\": 5,\n",
    "    \"cat\": 6,\n",
    "    \"dog\": 7\n",
    "}\n",
    "\n",
    "sentence = \"i i i i need some more coffee coffee coffee\"\n",
    "# 위 sentence\n",
    "_input = [vocab[w] for w in sentence.split()]  # [0, 0, 0, 0, 1, 2, 3, 4, 4, 4]\n",
    "\n",
    "vocab_size = len(vocab)   # 8\n",
    "\n",
    "one_hot = tf.one_hot(_input, vocab_size)\n",
    "print(one_hot.numpy())    # 원-핫 인코딩 벡터를 출력해 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원핫인코딩은 이해하기 어렵지 않게 잘 구분되어 입력되어 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 단어 임베딩, word embedding\n",
    "'분산 표현'의 개념을 차용해서 단어를 임베딩하는 것이 시도 되었는데, 주어 + [][] + '공부했다' 라는 문장처럼 사이에 '수학', '과학'과 같은 단어들이 들어갈 수 있다면 유사성을 유추하는 방법이다. 즉 임베딩레이어를 통해 연산이 되면, 유사도가 나온다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Weight\n",
      "[[-0.77032435  0.20424563]\n",
      " [-0.05968374  0.36324823]\n",
      " [-0.46036702  0.35536027]\n",
      " [ 0.29822004 -0.19714737]\n",
      " [-0.6681304   0.07589316]\n",
      " [-0.6337753  -0.57273227]\n",
      " [ 0.06780905  0.06207407]\n",
      " [-0.7113961  -0.00132269]]\n",
      "\n",
      "One-Hot Linear Result\n",
      "[[-0.77032435  0.20424563]\n",
      " [-0.77032435  0.20424563]\n",
      " [-0.77032435  0.20424563]\n",
      " [-0.77032435  0.20424563]\n",
      " [-0.05968374  0.36324823]\n",
      " [-0.46036702  0.35536027]\n",
      " [ 0.29822004 -0.19714737]\n",
      " [-0.6681304   0.07589316]\n",
      " [-0.6681304   0.07589316]\n",
      " [-0.6681304   0.07589316]]\n"
     ]
    }
   ],
   "source": [
    "distribution_size = 2   # 보기 좋게 2차원으로 분산 표현하도록 하죠!\n",
    "linear = tf.keras.layers.Dense(units=distribution_size, use_bias=False)\n",
    "one_hot_linear = linear(one_hot)\n",
    "\n",
    "print(\"Linear Weight\")\n",
    "print(linear.weights[0].numpy())\n",
    "\n",
    "print(\"\\nOne-Hot Linear Result\")\n",
    "print(one_hot_linear.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding을 진행할 문장: (1, 3)\n",
      "Embedding된 문장: (1, 3, 100)\n",
      "Embedding Layer의 Weight 형태: (64, 100)\n"
     ]
    }
   ],
   "source": [
    "some_words = tf.constant([[3, 57, 35]])\n",
    "# 3번 단어 / 57번 단어 / 35번 단어로 이루어진 한 문장입니다.\n",
    "\n",
    "print(\"Embedding을 진행할 문장:\", some_words.shape)\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=64, output_dim=100)\n",
    "# 총 64개의 단어를 포함한 Embedding 레이어를 선언할 것이고,\n",
    "# 각 단어는 100차원으로 분산 표현 할 것입니다.\n",
    "\n",
    "print(\"Embedding된 문장:\", embedding_layer(some_words).shape)\n",
    "print(\"Embedding Layer의 Weight 형태:\", embedding_layer.weights[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이전정보를 반영하는 신경망, RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문장이나 영상, 음성의 데이터는 이미지와 다르계 순차적인 특성을 갖고 있다.\n",
    "\n",
    "## 신경망이 이전정보를 반영하는 방법\n",
    "\n",
    "이전 정보를 반영하는 두 가지 방법론\n",
    "- (input , prev_hidden) -> hidden -> output\n",
    "  - 이전에 전부다 기억하는 방식\n",
    "- (input , prev_input) -> hidden -> output\n",
    "  - 바로 직전만을 기억하는 방식\n",
    "\n",
    "텐서플로우 프레임워크를 이용해 RNN을 만들어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN에 입력할 문장: What time is it ?\n",
      "Embedding을 위해 단어 매핑: [[2 3 0 1 4]]\n",
      "입력 문장 데이터 형태: (1, 5)\n",
      "\n",
      "Embedding 결과: (1, 5, 100)\n",
      "Embedding Layer의 Weight 형태: (5, 100)\n",
      "\n",
      "RNN 결과 (모든 Step Output): (1, 5, 64)\n",
      "RNN Layer의 Weight 형태: (100, 64)\n",
      "\n",
      "RNN 결과 (최종 Step Output): (1, 64)\n",
      "RNN Layer의 Weight 형태: (100, 64)\n"
     ]
    }
   ],
   "source": [
    "sentence = \"What time is it ?\"\n",
    "dic = {\n",
    "    \"is\": 0,\n",
    "    \"it\": 1,\n",
    "    \"What\": 2,\n",
    "    \"time\": 3,\n",
    "    \"?\": 4\n",
    "}\n",
    "\n",
    "print(\"RNN에 입력할 문장:\", sentence)\n",
    "\n",
    "sentence_tensor = tf.constant([[dic[word] for word in sentence.split()]])\n",
    "\n",
    "print(\"Embedding을 위해 단어 매핑:\", sentence_tensor.numpy())\n",
    "print(\"입력 문장 데이터 형태:\", sentence_tensor.shape)\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=len(dic), output_dim=100)\n",
    "emb_out = embedding_layer(sentence_tensor)\n",
    "\n",
    "print(\"\\nEmbedding 결과:\", emb_out.shape)\n",
    "print(\"Embedding Layer의 Weight 형태:\", embedding_layer.weights[0].shape)\n",
    "\n",
    "rnn_seq_layer = \\\n",
    "tf.keras.layers.SimpleRNN(units=64, return_sequences=True, use_bias=False)\n",
    "rnn_seq_out = rnn_seq_layer(emb_out)\n",
    "\n",
    "print(\"\\nRNN 결과 (모든 Step Output):\", rnn_seq_out.shape)\n",
    "print(\"RNN Layer의 Weight 형태:\", rnn_seq_layer.weights[0].shape)\n",
    "\n",
    "rnn_fin_layer = tf.keras.layers.SimpleRNN(units=64, use_bias=False)\n",
    "rnn_fin_out = rnn_fin_layer(emb_out)\n",
    "\n",
    "print(\"\\nRNN 결과 (최종 Step Output):\", rnn_fin_out.shape)\n",
    "print(\"RNN Layer의 Weight 형태:\", rnn_fin_layer.weights[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM 레이어 사용하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN은 음성인식, 언어모델링 이미지 캡쳐 생성 등에는 의미있는 성능을 보여주긴 했으나, 간단한 RNN 구조는 한계도 가지고 있는데, 장기 의존성을 다루지 못한다. 입력데이터가 길어질수록 데이터 앞쪽의 정보가 뒤쪽까지 전달이 잘 안되는 현상이다. RNN의 은닉층을 학습하는 과정에서 기울기 소실, vanishing gradient이 발생하기 때문이다.\n",
    "\n",
    "cell 이라는 메모리를 만들어서 은닉층에서 forget gate, input gate, gate gate, output gate를 통해 다음 순번의 은닉층에 연산이 되어지는 개념이다.\n",
    "\n",
    "forget Gate Layer : cell state의 기존 정보를 얼마나 잊어버릴지를 결정하는 gate\n",
    "input Gate Layer : 새롭게 들어온 정보를 기존 cell state에 얼마나 반영할지를 결정하는 gate\n",
    "output Gate Layer : 새롭게 만들어진 cell state를 새로운 hidden state에 얼마나 반영할지를 결정하는 gate\n",
    "\n",
    "LSTM의 변형을 주는 시도중에 GRU, Gated Recurrent Unit은 LSTM에서 cell state와 은닉층을 합치고, forget gate와 input gate를 통합했다.\n",
    "\n",
    "### GRU\n",
    "\n",
    "1. reset gate - 과거의 정보를 적당히 리셋시키는게 목적으로 sigmoid 함수를 출력해 은닉층에 곱해줍니다. LSTM에서 forget gate와 유사하다.\n",
    "\n",
    "2. update gate - gate gate와 input gate를 합쳐놓은 느낌으로 과거와 현재의 정보를 최신화 비율을 결정한다.\n",
    "\n",
    "3. candidate - 현 시점의 정보 후보군을 계산하는 단계\n",
    "\n",
    "## 양방향(Bidirectional) RNN\n",
    "\n",
    "'날이' '너무' [][][] '에어컨을' '켰다'와 같은 데이터가 있다면, 날이 너무 라는 앞 단어들로 추운지 더운지 예측하기 어렵다. 그렇지만 뒤에 에어컨을 켰다라고 하는 단어는 추운지 알 수 있다.\n",
    "\n",
    "양방향 RNN은 문장 분석이나 생성보다는 주로 기계번역같은 테스크에 유리하다. 번역기를 만들때는 Transformer네트워크를 주로 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문장 데이터 형태: (1, 5, 100)\n",
      "Bidirectional RNN 결과 (최종 Step Output): (1, 5, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sentence = \"What time is it ?\"\n",
    "dic = {\n",
    "    \"is\": 0,\n",
    "    \"it\": 1,\n",
    "    \"What\": 2,\n",
    "    \"time\": 3,\n",
    "    \"?\": 4\n",
    "}\n",
    "\n",
    "sentence_tensor = tf.constant([[dic[word] for word in sentence.split()]])\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=len(dic), output_dim=100)\n",
    "emb_out = embedding_layer(sentence_tensor)\n",
    "\n",
    "print(\"입력 문장 데이터 형태:\", emb_out.shape)\n",
    "\n",
    "bi_rnn = \\\n",
    "tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.SimpleRNN(units=64, use_bias=False, return_sequences=True)\n",
    ")\n",
    "bi_out = bi_rnn(emb_out)\n",
    "\n",
    "print(\"Bidirectional RNN 결과 (최종 Step Output):\", bi_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\n",
      "LSTM 결과 (모든 Step Output): (1, 5, 64)\n",
      "LSTM Layer의 Weight 형태: (100, 256)\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "\n",
      "LSTM 결과 (최종 Step Output): (1, 64)\n",
      "LSTM Layer의 Weight 형태: (100, 256)\n"
     ]
    }
   ],
   "source": [
    "lstm_seq_layer = tf.keras.layers.LSTM(units=64, return_sequences=True, use_bias=False)\n",
    "lstm_seq_out = lstm_seq_layer(emb_out)\n",
    "\n",
    "print(\"\\nLSTM 결과 (모든 Step Output):\", lstm_seq_out.shape)\n",
    "print(\"LSTM Layer의 Weight 형태:\", lstm_seq_layer.weights[0].shape)\n",
    "\n",
    "lstm_fin_layer = tf.keras.layers.LSTM(units=64, use_bias=False)\n",
    "lstm_fin_out = lstm_fin_layer(emb_out)\n",
    "\n",
    "print(\"\\nLSTM 결과 (최종 Step Output):\", lstm_fin_out.shape)\n",
    "print(\"LSTM Layer의 Weight 형태:\", lstm_fin_layer.weights[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
